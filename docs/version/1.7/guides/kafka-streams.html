<!DOCTYPE html>
<html>





<head>
  <title>Quarkus - Using Apache Kafka Streams - 1.7</title>
  <script id="adobe_dtm" src="https://www.redhat.com/dtm.js" type="text/javascript"></script>
  <script src="/assets/javascript/highlight.pack.js" type="text/javascript"></script>
  <META HTTP-EQUIV='X-XSS-Protection' CONTENT="1; mode=block">
  <META HTTP-EQUIV='X-Content-Type-Options' CONTENT="nosniff">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Quarkus: Supersonic Subatomic Java">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@QuarkusIO"> 
  <meta name="twitter:creator" content="@QuarkusIO">
  <meta property="og:url" content="https://quarkus.io/version/1.7/guides/kafka-streams" />
  <meta property="og:title" content="Quarkus - Using Apache Kafka Streams - 1.7" />
  <meta property="og:description" content="Quarkus: Supersonic Subatomic Java" />
  <meta property="og:image" content="https://quarkus.io/assets/images/quarkus_card.png" />
  
  <link rel="canonical" href="https://quarkus.io/guides/kafka-streams">
  <link rel="shortcut icon" type="image/png" href="/favicon.ico" >
  <link rel="stylesheet" href="/guides/stylesheet/config.css" />
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css" integrity="sha384-lKuwvrZot6UHsBSfcMvOkWwlCMgc0TaWr+30HWe3a4ltaBwTZhyTEggF5tJv8tbt" crossorigin="anonymous">
  <link rel="alternate" type="application/rss+xml"  href="/feed.xml" title="Quarkus">
  <script src="/assets/javascript/goan.js" type="text/javascript"></script>
  <script src="/assets/javascript/hl.js" type="text/javascript"></script>
</head>

<body class="guides">
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NJWS5L"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  <div class="nav-wrapper">
  <div class="grid-wrapper">
    <div class="width-12-12">
      <input type="checkbox" id="checkbox" />
      <nav id="main-nav" class="main-nav">
  <div class="container">
    <div class="logo-wrapper">
      
        <a href="/"><img src="/assets/images/quarkus_logo_horizontal_rgb_600px_reverse.png" class="project-logo" title="Quarkus"></a>
      
    </div>
    <label class="nav-toggle" for="checkbox">
      <i class="fa fa-bars"></i>
    </label>
    <div id="menu" class="menu">
      <span>
        <a href="/get-started/" class="">はじめに</a>
      </span>
      <span>
        <a href="/guides/" class="active">ガイド</a>
      </span>
      <span>
        <a href="/community/" class="">コミュニティ</a>
      </span>
      <span>
        <a href="/support/" class="">サポート</a>
      </span>
      <span>
        <a href="/blog/" class="">ブログ</a>
      </span>
      <span>
        <a href="https://code.quarkus.io" class="button-cta secondary white">コーディングを開始</a>
      </span>
    </div>
  </div>
      </nav>
    </div>
  </div>
</div>

  <div class="content">
    


<div class="grid-wrapper guide">
  <div class="grid__item width-9-12 width-12-12-mobile">
    <h1 class="text-caps">Quarkus - Using Apache Kafka Streams </h1>
  </div>
  <div class="grid__item width-3-12 align-self-center text-right hide-mobile">
    <label id="guide-version-label">Select Guide Version</label>
    <select id="guide-version-dropdown">
      
        
        
        
        
          <option value="main" >Main - SNAPSHOT</option>
        
      
        
        
        
        
          <option value="latest" >2.0 - Latest</option>
        
      
        
        
        
        
          <option value="1.11" >1.11</option>
        
      
        
        
        
        
          <option value="1.7" selected>1.7</option>
        
      
    </select>
  </div>
  <div class="width-12-12">
    <div class="hide-mobile toc"><ul class="sectlevel1">
<li><a href="#前提条件">前提条件</a></li>
<li><a href="#アーキテクチャ">アーキテクチャ</a></li>
<li><a href="#ソリューション">ソリューション</a></li>
<li><a href="#creating-the-producer-maven-project">Creating the Producer Maven Project</a>
<ul class="sectlevel2">
<li><a href="#温度値プロデューサー">温度値プロデューサー</a></li>
<li><a href="#トピック構成">トピック構成</a></li>
</ul>
</li>
<li><a href="#アグリゲータmavenプロジェクトの作成">アグリゲータMavenプロジェクトの作成</a>
<ul class="sectlevel2">
<li><a href="#パイプラインの実装">パイプラインの実装</a></li>
</ul>
</li>
<li><a href="#アプリケーションのビルドと実行">アプリケーションのビルドと実行</a></li>
<li><a href="#インタラクティブクエリ">インタラクティブクエリ</a></li>
<li><a href="#スケールアウト">スケールアウト</a>
<ul class="sectlevel2">
<li><a href="#readiness-health-check">Readiness health check</a></li>
</ul>
</li>
</ul></div>
    <div>
      <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>このガイドでは、QuarkusアプリケーションがApache Kafka Streams APIを利用して、Apache
Kafkaベースのストリーム処理アプリケーションを実装する方法を説明します。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="前提条件"><a class="anchor" href="#前提条件"></a>前提条件</h2>
<div class="sectionbody">
<div class="paragraph">
<p>このガイドを完成させるには、以下が必要です:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>三十分以内</p>
</li>
<li>
<p>IDE</p>
</li>
<li>
<p>JDK 1.8+ がインストールされ、 <code>JAVA_HOME</code>  が適切に設定されていること</p>
</li>
<li>
<p>Apache Maven 3.6.2+</p>
</li>
<li>
<p>Docker Compose to start an Apache Kafka development cluster</p>
</li>
<li>
<p>ネイティブモードで実行する場合は、GraalVM がインストールされていること</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>事前に <a href="https://github.com/quarkusio/quarkus-quickstarts/tree/main/kafka-quickstart">Kafka quickstart</a>
を読んでおくことをお勧めします。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Kafka Streams用のQuarkusエクステンションを使用すると、Quarkus Dev
Modeをサポートすることで、開発期間を非常に短縮することができます(例: <code>./mvnw compile quarkus:dev</code>
を参照)。Kafka Streamsトポロジーのコードを変更した後、次の入力メッセージが到着すると、アプリケーションが自動的にリロードされます。</p>
</div>
<div class="paragraph">
<p>推奨される開発セットアップは、処理されたトピックに対して一定の間隔 (たとえば毎秒) でテストメッセージを作成するプロデューサを用意し、
<code>kafkacat</code> のようなツールを使用してストリーミング
アプリケーションの出力トピックを観察することです。開発モードを使用すると、保存時にストリーミングアプリケーションの最新バージョンによって生成された出力トピッ
ク上のメッセージを即座に見ることができます。</p>
</div>
<div class="paragraph">
<p>最高の開発環境を実現するために、以下の設定を Kafka ブローカーに適用することをお勧めします。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">group.min.session.timeout.ms=250</code></pre>
</div>
</div>
<div class="paragraph">
<p>また、以下の設定をQuarkusの `application.properties`で指定します。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">kafka-streams.consumer.session.timeout.ms=250
kafka-streams.consumer.heartbeat.interval.ms=200</code></pre>
</div>
</div>
<div class="paragraph">
<p>これらの設定を併用することで、アプリケーションを開発モードで再起動した後に、非常に迅速にブローカに再接続できるようになります。</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="アーキテクチャ"><a class="anchor" href="#アーキテクチャ"></a>アーキテクチャ</h2>
<div class="sectionbody">
<div class="paragraph">
<p>このガイドでは、(ランダムな)温度値を 1 つのコンポーネント ( <code>generator</code> )
で生成します。これらの値は、与えられた気象観測所に関連付けられ、Kafka トピック ( <code>temperature-values</code> )
に書き込まれます。別のトピック ( <code>weather-stations</code> ) には、気象観測所自体に関するマスターデータ (id と名前)
だけが格納されています。</p>
</div>
<div class="paragraph">
<p>2 つ目のコンポーネント ( <code>aggregator</code> ) は、2 つの Kafka トピックから読み込み、ストリーミングパイプラインで処理します。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>ウェザーステーション ID では、この2つのトピックが結合されています。</p>
</li>
<li>
<p>各気象台ごとに最低、最高、平均気温が決定されます。</p>
</li>
<li>
<p>この集約されたデータは、第三のトピック ( <code>temperatures-aggregated</code> ) に書き出されます。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>出力トピックを検査することで、データを調べることができます。Kafka Streams の
<a href="https://kafka.apache.org/22/documentation/streams/developer-guide/interactive-queries.html">対話型クエリ</a>
を公開することで、各気象観測所の最新の結果を単純な REST クエリで取得することができます。</p>
</div>
<div class="paragraph">
<p>全体的なアーキテクチャはこんな感じです。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/kafka-streams-guide-architecture.png" alt="アーキテクチャ">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="ソリューション"><a class="anchor" href="#ソリューション"></a>ソリューション</h2>
<div class="sectionbody">
<div class="paragraph">
<p>次の章で紹介する手順に沿って、ステップを踏んでアプリを作成することをお勧めします。ただし、完成した例にそのまま進んでも構いません。</p>
</div>
<div class="paragraph">
<p>Gitレポジトリをクローンするか <code>git clone <a href="https://github.com/quarkusio/quarkus-quickstarts.git" class="bare">https://github.com/quarkusio/quarkus-quickstarts.git</a></code> 、
<a href="https://github.com/quarkusio/quarkus-quickstarts/archive/main.zip">アーカイブ</a> をダウンロードします。</p>
</div>
<div class="paragraph">
<p>ソリューションは <code>kafka-streams-quickstart</code>
<a href="https://github.com/quarkusio/quarkus-quickstarts/tree/main/kafka-streams-quickstart">ディレクトリ</a> にあります。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="creating-the-producer-maven-project"><a class="anchor" href="#creating-the-producer-maven-project"></a>Creating the Producer Maven Project</h2>
<div class="sectionbody">
<div class="paragraph">
<p>まず、温度値プロデューサを持つ新しいプロジェクトが必要です。以下のコマンドで新規プロジェクトを作成します。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">mvn io.quarkus:quarkus-maven-plugin:1.7.6.Final:create \
    -DprojectGroupId=org.acme \
    -DprojectArtifactId=kafka-streams-quickstart-producer \
    -Dextensions="kafka" \
    &amp;&amp; mv kafka-streams-quickstart-producer producer</code></pre>
</div>
</div>
<div class="paragraph">
<p>このコマンドにより、Maven プロジェクトが作成され、Reactive Messaging と Kafka
コネクターエクステンションをインポートします。</p>
</div>
<div class="paragraph">
<p>すでに Quarkus プロジェクトが設定されている場合は、プロジェクトのベースディレクトリーで以下のコマンドを実行して、プロジェクトに
<code>smallrye-reactive-messaging-kafka</code> エクステンションを追加することができます。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">./mvnw quarkus:add-extension -Dextensions="kafka"</code></pre>
</div>
</div>
<div class="paragraph">
<p>これにより、 <code>pom.xml</code> に以下が追加されます:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;
    &lt;artifactId&gt;quarkus-smallrye-reactive-messaging-kafka&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="sect2">
<h3 id="温度値プロデューサー"><a class="anchor" href="#温度値プロデューサー"></a>温度値プロデューサー</h3>
<div class="paragraph">
<p>以下の内容の
<code>producer/src/main/java/org/acme/kafka/streams/producer/generator/ValuesGenerator.java</code>
ファイルを作成します。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme.kafka.streams.producer.generator;

import java.math.BigDecimal;
import java.math.RoundingMode;
import java.time.Instant;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.Random;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Outgoing;
import org.jboss.logging.Logger;

import io.reactivex.Flowable;
import io.smallrye.reactive.messaging.kafka.KafkaRecord;

/**
 * A bean producing random temperature data every second.
 * The values are written to a Kafka topic (temperature-values).
 * Another topic contains the name of weather stations (weather-stations).
 * The Kafka configuration is specified in the application configuration.
 */
@ApplicationScoped
public class ValuesGenerator {

    private static final Logger LOG = Logger.getLogger(ValuesGenerator.class);

    private Random random = new Random();

    private List&lt;WeatherStation&gt; stations = Collections.unmodifiableList(
            Arrays.asList(
                    new WeatherStation(1, "Hamburg", 13),
                    new WeatherStation(2, "Snowdonia", 5),
                    new WeatherStation(3, "Boston", 11),
                    new WeatherStation(4, "Tokio", 16),
                    new WeatherStation(5, "Cusco", 12),
                    new WeatherStation(6, "Svalbard", -7),
                    new WeatherStation(7, "Porthsmouth", 11),
                    new WeatherStation(8, "Oslo", 7),
                    new WeatherStation(9, "Marrakesh", 20)
            ));


    @Outgoing("temperature-values")                             <i class="conum" data-value="1"></i><b>(1)</b>
    public Flowable&lt;KafkaRecord&lt;Integer, String&gt;&gt; generate() {

        return Flowable.interval(500, TimeUnit.MILLISECONDS)    <i class="conum" data-value="2"></i><b>(2)</b>
                .onBackpressureDrop()
                .map(tick -&gt; {
                    WeatherStation station = stations.get(random.nextInt(stations.size()));
                    double temperature = BigDecimal.valueOf(random.nextGaussian() * 15 + station.averageTemperature)
                            .setScale(1, RoundingMode.HALF_UP)
                            .doubleValue();

                    LOG.infov("station: {0}, temperature: {1}", station.name, temperature);
                    return KafkaRecord.of(station.id, Instant.now() + ";" + temperature);
                });
    }

    @Outgoing("weather-stations")                               <i class="conum" data-value="3"></i><b>(3)</b>
    public Flowable&lt;KafkaRecord&lt;Integer, String&gt;&gt; weatherStations() {
        List&lt;KafkaRecord&lt;Integer, String&gt;&gt; stationsAsJson = stations.stream()
            .map(s -&gt; KafkaRecord.of(
                    s.id,
                    "{ \"id\" : " + s.id +
                    ", \"name\" : \"" + s.name + "\" }"))
            .collect(Collectors.toList());

        return Flowable.fromIterable(stationsAsJson);
    };

    private static class WeatherStation {

        int id;
        String name;
        int averageTemperature;

        public WeatherStation(int id, String name, int averageTemperature) {
            this.id = id;
            this.name = name;
            this.averageTemperature = averageTemperature;
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Instruct Reactive Messaging to dispatch the items from the returned
<code>Flowable</code> to <code>temperature-values</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The method returns a RX Java 2 <em>stream</em> (<code>Flowable</code>) emitting a random
temperature value every 0.5 seconds.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Instruct Reactive Messaging to dispatch the items from the returned
<code>Flowable</code> (static list of weather stations) to <code>weather-stations</code>.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>この 2 つのメソッドは、それぞれ <code>temperature-values</code> と <code>weather-stations</code>
という名前のストリームにアイテムが送信される <em>リアクティブストリーム</em> を返します。</p>
</div>
</div>
<div class="sect2">
<h3 id="トピック構成"><a class="anchor" href="#トピック構成"></a>トピック構成</h3>
<div class="paragraph">
<p>2つのチャンネルは、Quarkus設定ファイル <code>application.properties</code>
を使用してKafkaトピックにマッピングされます。そのためには、ファイル
<code>producer/src/main/resources/application.properties</code> に次のように追加します。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs"># Configure the Kafka broker location
kafka.bootstrap.servers=localhost:9092

mp.messaging.outgoing.temperature-values.connector=smallrye-kafka
mp.messaging.outgoing.temperature-values.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.temperature-values.value.serializer=org.apache.kafka.common.serialization.StringSerializer

mp.messaging.outgoing.weather-stations.connector=smallrye-kafka
mp.messaging.outgoing.weather-stations.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer
mp.messaging.outgoing.weather-stations.value.serializer=org.apache.kafka.common.serialization.StringSerializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>これは、Kafka ブートストラップサーバー、2 つのトピック、および対応する
(デ)シリアライザを設定します。さまざまな設定オプションの詳細については、Kafka ドキュメントの
<a href="https://kafka.apache.org/documentation/#producerconfigs">Producer 設定</a> と
<a href="https://kafka.apache.org/documentation/#consumerconfigs">Consumer 設定</a>
のセクションを参照してください。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="アグリゲータmavenプロジェクトの作成"><a class="anchor" href="#アグリゲータmavenプロジェクトの作成"></a>アグリゲータMavenプロジェクトの作成</h2>
<div class="sectionbody">
<div class="paragraph">
<p>プロデューサアプリケーションを用意したら、Kafka Streams
パイプラインを実行するアグリゲータアプリケーションを実装しましょう。このように別のプロジェクトを作成します。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">mvn io.quarkus:quarkus-maven-plugin:1.7.6.Final:create \
    -DprojectGroupId=org.acme \
    -DprojectArtifactId=kafka-streams-quickstart-aggregator \
    -Dextensions="kafka-streams,resteasy-jsonb" \
    &amp;&amp; mv kafka-streams-quickstart-aggregator aggregator</code></pre>
</div>
</div>
<div class="paragraph">
<p>This creates the <code>aggregator</code> project with the Quarkus extension for Kafka
Streams and with RESTEasy support for JSON-B.</p>
</div>
<div class="paragraph">
<p>すでにQuarkusプロジェクトが設定されている場合は、プロジェクトのベースディレクトリーで以下のコマンドを実行することで、プロジェクトに
<code>kafka-streams</code> エクステンションを追加することができます。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">./mvnw quarkus:add-extension -Dextensions="kafka-streams"</code></pre>
</div>
</div>
<div class="paragraph">
<p>これにより、 <code>pom.xml</code> に以下が追加されます:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;
    &lt;artifactId&gt;quarkus-kafka-streams&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="sect2">
<h3 id="パイプラインの実装"><a class="anchor" href="#パイプラインの実装"></a>パイプラインの実装</h3>
<div class="paragraph">
<p>ストリーム処理アプリケーションの実装を開始しましょう。温度測定、気象観測所を表現し、集約された値を追跡するためのいくつかの値オブジェクトを作成することから始めましょう。</p>
</div>
<div class="paragraph">
<p>まず、次の内容でファイル
<code>aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/WeatherStation.java</code>
を作成します。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme.kafka.streams.aggregator.model;

import io.quarkus.runtime.annotations.RegisterForReflection;

@RegisterForReflection <i class="conum" data-value="1"></i><b>(1)</b>
public class WeatherStation {

    public int id;
    public String name;
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><code>@RegisterForReflection</code>
アノテーションを追加することで、ネイティブモードでアプリケーションを実行しているときに、この型がリフレクションによってインスタンス化されることが保証されます。</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>次に、指定されたステーションの温度測定値を表すファイル
<code>aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/TemperatureMeasurement.java</code>
です。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme.kafka.streams.aggregator.model;

import java.time.Instant;

public class TemperatureMeasurement {

    public int stationId;
    public String stationName;
    public Instant timestamp;
    public double value;

    public TemperatureMeasurement(int stationId, String stationName, Instant timestamp,
            double value) {
        this.stationId = stationId;
        this.stationName = stationName;
        this.timestamp = timestamp;
        this.value = value;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>そして最後に
<code>aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/Aggregation.java</code>
、イベントがストリーミング・パイプラインで処理されている間、集約された値を追跡するために使用されます。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme.kafka.streams.aggregator.model;

import java.math.BigDecimal;
import java.math.RoundingMode;

import io.quarkus.runtime.annotations.RegisterForReflection;

@RegisterForReflection
public class Aggregation {

    public int stationId;
    public String stationName;
    public double min = Double.MAX_VALUE;
    public double max = Double.MIN_VALUE;
    public int count;
    public double sum;
    public double avg;

    public Aggregation updateFrom(TemperatureMeasurement measurement) {
        stationId = measurement.stationId;
        stationName = measurement.stationName;

        count++;
        sum += measurement.value;
        avg = BigDecimal.valueOf(sum / count)
                .setScale(1, RoundingMode.HALF_UP).doubleValue();

        min = Math.min(min, measurement.value);
        max = Math.max(max, measurement.value);

        return this;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>次に、実際のストリーミングクエリの実装自体を
<code>aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/TopologyProducer.java</code>
ファイルで作成してみましょう。そのために必要なのは、Kafka Streams <code>Topology</code> を返す CDI
プロデューサメソッドを宣言することだけです。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme.kafka.streams.aggregator.streams;

import java.time.Instant;

import javax.enterprise.context.ApplicationScoped;
import javax.enterprise.inject.Produces;

import org.acme.kafka.streams.aggregator.model.Aggregation;
import org.acme.kafka.streams.aggregator.model.TemperatureMeasurement;
import org.acme.kafka.streams.aggregator.model.WeatherStation;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.GlobalKTable;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.streams.state.KeyValueBytesStoreSupplier;
import org.apache.kafka.streams.state.Stores;

import io.quarkus.kafka.client.serialization.JsonbSerde;

@ApplicationScoped
public class TopologyProducer {

    static final String WEATHER_STATIONS_STORE = "weather-stations-store";

    private static final String WEATHER_STATIONS_TOPIC = "weather-stations";
    private static final String TEMPERATURE_VALUES_TOPIC = "temperature-values";
    private static final String TEMPERATURES_AGGREGATED_TOPIC = "temperatures-aggregated";

    @Produces
    public Topology buildTopology() {
        StreamsBuilder builder = new StreamsBuilder();

        JsonbSerde&lt;WeatherStation&gt; weatherStationSerde = new JsonbSerde&lt;&gt;(
                WeatherStation.class);
        JsonbSerde&lt;Aggregation&gt; aggregationSerde = new JsonbSerde&lt;&gt;(Aggregation.class);

        KeyValueBytesStoreSupplier storeSupplier = Stores.persistentKeyValueStore(
                WEATHER_STATIONS_STORE);

        GlobalKTable&lt;Integer, WeatherStation&gt; stations = builder.globalTable( <i class="conum" data-value="1"></i><b>(1)</b>
                WEATHER_STATIONS_TOPIC,
                Consumed.with(Serdes.Integer(), weatherStationSerde));

        builder.stream(                                                       <i class="conum" data-value="2"></i><b>(2)</b>
                        TEMPERATURE_VALUES_TOPIC,
                        Consumed.with(Serdes.Integer(), Serdes.String())
                )
                .join(                                                        <i class="conum" data-value="3"></i><b>(3)</b>
                        stations,
                        (stationId, timestampAndValue) -&gt; stationId,
                        (timestampAndValue, station) -&gt; {
                            String[] parts = timestampAndValue.split(";");
                            return new TemperatureMeasurement(station.id, station.name,
                                    Instant.parse(parts[0]), Double.valueOf(parts[1]));
                        }
                )
                .groupByKey()                                                 <i class="conum" data-value="4"></i><b>(4)</b>
                .aggregate(                                                   <i class="conum" data-value="5"></i><b>(5)</b>
                        Aggregation::new,
                        (stationId, value, aggregation) -&gt; aggregation.updateFrom(value),
                        Materialized.&lt;Integer, Aggregation&gt; as(storeSupplier)
                            .withKeySerde(Serdes.Integer())
                            .withValueSerde(aggregationSerde)
                )
                .toStream()
                .to(                                                          <i class="conum" data-value="6"></i><b>(6)</b>
                        TEMPERATURES_AGGREGATED_TOPIC,
                        Produced.with(Serdes.Integer(), aggregationSerde)
                );

        return builder.build();
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><code>weather-stations</code> テーブルは、各気象台の現在の状態を表す <code>GlobalKTable</code> に読み込まれます。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td><code>temperature-values</code> トピックは <code>KStream</code>
に読み込まれます。このトピックに新しいメッセージが到着するたびに、パイプラインはこの測定のために処理されます。</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td><code>temperature-values</code> トピックからのメッセージは、トピックのキー (ウェザーステーション ID)
を使用して、対応するウェザーステーションと結合されます。</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>値はメッセージキー(ウェザーステーションID)によってグループ化されます。</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>各グループ内では、最小値と最大値を追跡し、そのステーションのすべての測定値の平均値を計算することで、そのステーションのすべての測定値が集約されます(
<code>Aggregation</code> タイプを参照)。</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>パイプラインの結果は <code>temperatures-aggregated</code> トピックに書き出しています。</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Kafka Streams エクステンションは、Quarkusの設定ファイル <code>application.properties</code> で設定します。ファイル
<code>aggregator/src/main/resources/application.properties</code> を以下の内容で作成します。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">quarkus.kafka-streams.bootstrap-servers=localhost:9092
quarkus.kafka-streams.application-server=${hostname}:8080
quarkus.kafka-streams.topics=weather-stations,temperature-values

# pass-through options
kafka-streams.cache.max.bytes.buffering=10240
kafka-streams.commit.interval.ms=1000
kafka-streams.metadata.max.age.ms=500
kafka-streams.auto.offset.reset=earliest
kafka-streams.metrics.recording.level=DEBUG</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>quarkus.kafka-streams</code> <code>bootstrap-servers</code> と は、それぞれ Kafka Streams プロパティー と
にマップされます。 <code>application-server</code> <code>bootstrap.servers</code> <code>application.server</code>
<code>topics</code> は Quarkus に固有のもので、アプリケーションは Kafka Streams
エンジンを起動する前に、指定したすべてのトピックが存在するのを待ちます。これは、アプリケーションの起動時にまだ存在しないトピックの作成をグレースフルに待つために行われます。</p>
</div>
<div class="paragraph">
<p><code>kafka-streams</code> ネームスペース内のすべてのプロパティーは、そのまま Kafka Streams
エンジンに渡されます。プロパティーの値を変更するには、アプリケーションの再構築が必要です。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="アプリケーションのビルドと実行"><a class="anchor" href="#アプリケーションのビルドと実行"></a>アプリケーションのビルドと実行</h2>
<div class="sectionbody">
<div class="paragraph">
<p><code>producer</code> と <code>aggregator</code> のアプリケーションをビルドできるようになりました。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">./mvnw clean package -f producer/pom.xml
./mvnw clean package -f aggregator/pom.xml</code></pre>
</div>
</div>
<div class="paragraph">
<p>Quarkusのdevモードを使ってホストマシン上で直接実行するのではなく、コンテナーイメージにパッケージ化してDocker
Compose経由で起動します。これは、後で <code>aggregator</code> のアグリゲーションを複数のノードにスケーリングすることを実証するために行います。</p>
</div>
<div class="paragraph">
<p>Quarkusがデフォルトで作成した <code>Dockerfile</code> は、Kafka Streamsパイプラインを実行するために、 <code>aggregator</code>
アプリケーションに1つの調整が必要です。そのためには、 <code>aggregator/src/main/docker/Dockerfile.jvm</code>
ファイルを編集して、 <code>FROM fabric8/java-alpine-openjdk8-jre</code> の行を <code>FROM
fabric8/java-centos-openjdk8-jdk</code> に置き換えます。</p>
</div>
<div class="paragraph">
<p>次に、2 つのアプリケーションを起動するための Docker Compose ファイル ( <code>docker-compose.yaml</code> )
を作成し、Apache Kafka と ZooKeeper と同様に以下のようにします。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">version: '3.5'

services:
  zookeeper:
    image: strimzi/kafka:0.11.3-kafka-2.1.0
    command: [
      "sh", "-c",
      "bin/zookeeper-server-start.sh config/zookeeper.properties"
    ]
    ports:
      - "2181:2181"
    environment:
      LOG_DIR: /tmp/logs
    networks:
      - kafkastreams-network
  kafka:
    image: strimzi/kafka:0.11.3-kafka-2.1.0
    command: [
      "sh", "-c",
      "bin/kafka-server-start.sh config/server.properties --override listeners=$${KAFKA_LISTENERS} --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT} --override num.partitions=$${KAFKA_NUM_PARTITIONS}"
    ]
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      LOG_DIR: "/tmp/logs"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_NUM_PARTITIONS: 3
    networks:
      - kafkastreams-network

  producer:
    image: quarkus-quickstarts/kafka-streams-producer:1.0
    build:
      context: producer
      dockerfile: src/main/docker/Dockerfile.${QUARKUS_MODE:-jvm}
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    networks:
      - kafkastreams-network

  aggregator:
    image: quarkus-quickstarts/kafka-streams-aggregator:1.0
    build:
      context: aggregator
      dockerfile: src/main/docker/Dockerfile.${QUARKUS_MODE:-jvm}
    environment:
      QUARKUS_KAFKA_STREAMS_BOOTSTRAP_SERVERS: kafka:9092
    networks:
      - kafkastreams-network

networks:
  kafkastreams-network:
    name: ks</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>producer</code> と <code>aggregator</code> のコンテナーイメージをビルドして、すべてのコンテナーを起動するには、 <code>docker-compose
up --build</code> を実行します。</p>
</div>
<div class="paragraph">
<p><code>producer</code> アプリケーションから、"temperature-values"
トピックに送信されたメッセージに関するログステートメントが表示されるはずです。</p>
</div>
<div class="paragraph">
<p>ここで <em>debezium/tooling</em>
イメージのインスタンスを実行し、他のすべてのコンテナーが実行しているのと同じネットワークにアタッチします。このイメージは、 <em>kafkacat</em> や
<em>httpie</em> などの便利なツールを提供しています。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">docker run --tty --rm -i --network ks debezium/tooling:1.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>ツールコンテナー内で、 <em>kafkacatを</em> 実行して、ストリーミングパイプラインの結果を調べます。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">kafkacat -b kafka:9092 -C -o beginning -q -t temperatures-aggregated

{"avg":34.7,"count":4,"max":49.4,"min":16.8,"stationId":9,"stationName":"Marrakesh","sum":138.8}
{"avg":15.7,"count":1,"max":15.7,"min":15.7,"stationId":2,"stationName":"Snowdonia","sum":15.7}
{"avg":12.8,"count":7,"max":25.5,"min":-13.8,"stationId":7,"stationName":"Porthsmouth","sum":89.7}
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>プロデューサが温度測定値を出力し続けると、新しい値が表示され、送信トピックの各値は、表現された気象観測所の最小、最大、および平均温度値を表示します。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="インタラクティブクエリ"><a class="anchor" href="#インタラクティブクエリ"></a>インタラクティブクエリ</h2>
<div class="sectionbody">
<div class="paragraph">
<p><code>temperatures-aggregated</code>
のトピックを購読することは、新しい気温の値に反応するための素晴らしい方法です。しかし、特定の気象観測所の最新の集計値だけに興味があるのであれば、少しもったいないです。そこで、Kafka
Streams の対話型クエリが威力を発揮します。ステートストアをクエリするシンプルな REST エンドポイントを公開することで、Kafka
トピックを購読しなくても最新の集計結果を取得することができます。</p>
</div>
<div class="paragraph">
<p>まず、ファイル
<code>aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/InteractiveQueries.java</code>
内に <code>InteractiveQueries</code> を作成することから始めましょう。</p>
</div>
<div class="paragraph">
<p><code>KafkaStreamsPipeline</code> クラスに、与えられたキーの現在の状態を取得するメソッドをもう一つ追加しました。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme.kafka.streams.aggregator.streams;

import javax.enterprise.context.ApplicationScoped;
import javax.inject.Inject;

import org.acme.kafka.streams.aggregator.model.Aggregation;
import org.acme.kafka.streams.aggregator.model.WeatherStationData;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.errors.InvalidStateStoreException;
import org.apache.kafka.streams.state.QueryableStoreTypes;
import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;

@ApplicationScoped
public class InteractiveQueries {

    @Inject
    KafkaStreams streams;

    public GetWeatherStationDataResult getWeatherStationData(int id) {
        Aggregation result = getWeatherStationStore().get(id);

        if (result != null) {
            return GetWeatherStationDataResult.found(WeatherStationData.from(result)); <i class="conum" data-value="1"></i><b>(1)</b>
        }
        else {
            return GetWeatherStationDataResult.notFound();                             <i class="conum" data-value="2"></i><b>(2)</b>
        }
    }

    private ReadOnlyKeyValueStore&lt;Integer, Aggregation&gt; getWeatherStationStore() {
        while (true) {
            try {
                return streams.store(TopologyProducer.WEATHER_STATIONS_STORE, QueryableStoreTypes.keyValueStore());
            } catch (InvalidStateStoreException e) {
                // ignore, store not ready yet
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>指定されたステーションIDの値が見つかったので、その値が返されます。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>存在しないステーションがクエリされたか、指定されたステーションに測定がまだ存在しないため、値が見つかりませんでした。</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>また、メソッドの戻り値の型もファイル
<code>aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/GetWeatherStationDataResult.java</code>
に作成します。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme.kafka.streams.aggregator.streams;

import java.util.Optional;
import java.util.OptionalInt;

import org.acme.kafka.streams.aggregator.model.WeatherStationData;

public class GetWeatherStationDataResult {

    private static GetWeatherStationDataResult NOT_FOUND =
            new GetWeatherStationDataResult(null);

    private final WeatherStationData result;

    private GetWeatherStationDataResult(WeatherStationData result) {
        this.result = result;
    }

    public static GetWeatherStationDataResult found(WeatherStationData data) {
        return new GetWeatherStationDataResult(data);
    }

    public static GetWeatherStationDataResult notFound() {
        return NOT_FOUND;
    }

    public Optional&lt;WeatherStationData&gt; getResult() {
        return Optional.ofNullable(result);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>また、気象台の実際の集計結果を表す
<code>aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/WeatherStationData.java</code>
を作成します。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme.kafka.streams.aggregator.model;

import io.quarkus.runtime.annotations.RegisterForReflection;

@RegisterForReflection
public class WeatherStationData {

    public int stationId;
    public String stationName;
    public double min = Double.MAX_VALUE;
    public double max = Double.MIN_VALUE;
    public int count;
    public double avg;

    private WeatherStationData(int stationId, String stationName, double min, double max,
            int count, double avg) {
        this.stationId = stationId;
        this.stationName = stationName;
        this.min = min;
        this.max = max;
        this.count = count;
        this.avg = avg;
    }

    public static WeatherStationData from(Aggregation aggregation) {
        return new WeatherStationData(
                aggregation.stationId,
                aggregation.stationName,
                aggregation.min,
                aggregation.max,
                aggregation.count,
                aggregation.avg);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>これで、 <code>getWeatherStationData()</code> を呼び出してクライアントにデータを返すシンプルな REST エンドポイント (
<code>aggregator/src/main/java/org/acme/kafka/streams/aggregator/rest/WeatherStationEndpoint.java</code>
) を追加することができます。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme.kafka.streams.aggregator.rest;

import java.net.URI;
import java.net.URISyntaxException;
import java.util.List;

import javax.enterprise.context.ApplicationScoped;
import javax.inject.Inject;
import javax.ws.rs.Consumes;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.Response.Status;

import org.acme.kafka.streams.aggregator.streams.GetWeatherStationDataResult;
import org.acme.kafka.streams.aggregator.streams.KafkaStreamsPipeline;

@ApplicationScoped
@Path("/weather-stations")
public class WeatherStationEndpoint {

    @Inject
    InteractiveQueries interactiveQueries;

    @GET
    @Path("/data/{id}")
    @Consumes(MediaType.APPLICATION_JSON)
    @Produces(MediaType.APPLICATION_JSON)
    public Response getWeatherStationData(@PathParam("id") int id) {
        GetWeatherStationDataResult result = interactiveQueries.getWeatherStationData(id);

        if (result.getResult().isPresent()) {  <i class="conum" data-value="1"></i><b>(1)</b>
            return Response.ok(result.getResult().get()).build();
        }
        else {
            return Response.status(Status.NOT_FOUND.getStatusCode(),
                    "No data found for weather station " + id).build();
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>値が取得されたかどうかに応じて、その値を返すか、404 レスポンスを返すかのどちらかを選択します。</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>このコードを用意して、Docker Composeでアプリケーションと <code>aggregator</code> サービスをリビルドしましょう。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">./mvnw clean package -f aggregator/pom.xml
docker-compose stop aggregator
docker-compose up --build -d</code></pre>
</div>
</div>
<div class="paragraph">
<p>これにより、 <code>aggregator</code> コンテナーが再構築され、サービスが再起動されます。これが完了したら、サービスの REST API
を呼び出して、既存のステーションの 1 つの温度データを取得することができます。そのためには、前に起動したツーリングコンテナで <code>httpie</code>
を使用します。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">http aggregator:8080/weather-stations/data/1

HTTP/1.1 200 OK
Connection: keep-alive
Content-Length: 85
Content-Type: application/json
Date: Tue, 18 Jun 2019 19:29:16 GMT

{
    "avg": 12.9,
    "count": 146,
    "max": 41.0,
    "min": -25.6,
    "stationId": 1,
    "stationName": "Hamburg"
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="スケールアウト"><a class="anchor" href="#スケールアウト"></a>スケールアウト</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Kafka Streams
の非常に興味深い特性は、それらがスケールアウト可能であるということです。つまり、同じパイプラインを実行している複数のアプリケーションインスタンス間で負荷や状態を分散させることができます。各ノードには集約結果のサブセットが含まれますが、Kafka
Streams は与えられたキーをホストしているノードの情報を取得するための
<a href="https://kafka.apache.org/22/documentation/streams/developer-guide/interactive-queries.html#querying-remote-state-stores-for-the-entire-app">API</a>
を提供しています。アプリケーションは、他のインスタンスから直接データを取得するか、クライアントにその他のノードの場所を指定するだけです。</p>
</div>
<div class="paragraph">
<p><code>aggregator</code> アプリケーションの複数のインスタンスを起動すると、全体のアーキテクチャがこのようになります。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/kafka-streams-guide-architecture-distributed.png" alt="アーキテクチャ" width="with multiple aggregator nodes">
</div>
</div>
<div class="paragraph">
<p><code>InteractiveQueries</code> クラスは、この分散型アーキテクチャ用に少し調整する必要があります。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public GetWeatherStationDataResult getWeatherStationData(int id) {
    StreamsMetadata metadata = streams.metadataForKey(                  <i class="conum" data-value="1"></i><b>(1)</b>
            TopologyProducer.WEATHER_STATIONS_STORE,
            id,
            Serdes.Integer().serializer()
    );

    if (metadata == null || metadata == StreamsMetadata.NOT_AVAILABLE) {
        LOG.warn("Found no metadata for key {}", id);
        return GetWeatherStationDataResult.notFound();
    }
    else if (metadata.host().equals(host)) {                            <i class="conum" data-value="2"></i><b>(2)</b>
        LOG.info("Found data for key {} locally", id);
        Aggregation result = getWeatherStationStore().get(id);

        if (result != null) {
            return GetWeatherStationDataResult.found(WeatherStationData.from(result));
        }
        else {
            return GetWeatherStationDataResult.notFound();
        }
    }
    else {                                                              <i class="conum" data-value="3"></i><b>(3)</b>
        LOG.info(
            "Found data for key {} on remote host {}:{}",
            id,
            metadata.host(),
            metadata.port()
        );
        return GetWeatherStationDataResult.foundRemotely(metadata.host(), metadata.port());
    }
}

public List&lt;PipelineMetadata&gt; getMetaData() {                           <i class="conum" data-value="4"></i><b>(4)</b>
    return streams.allMetadataForStore(TopologyProducer.WEATHER_STATIONS_STORE)
            .stream()
            .map(m -&gt; new PipelineMetadata(
                    m.hostInfo().host() + ":" + m.hostInfo().port(),
                    m.topicPartitions()
                        .stream()
                        .map(TopicPartition::toString)
                        .collect(Collectors.toSet()))
            )
            .collect(Collectors.toList());
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>与えられたウェザーステーションIDのストリームメタデータが取得されます。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>与えられたキー(ウェザーステーションID)はローカルのアプリケーションノードによって管理されています。</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>与えられたキーは別のアプリケーションノードによって管理されています; この場合、そのノードに関する情報(ホストとポート)が返されます。</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td><code>getMetaData()</code> メソッドが追加され、アプリケーション・クラスター内の全ノードのリストを呼び出し元に提供するようになりました。</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>GetWeatherStationDataResult</code> のタイプは、それに合わせて調整する必要があります。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme.kafka.streams.aggregator.streams;

import java.util.Optional;
import java.util.OptionalInt;

import org.acme.kafka.streams.aggregator.model.WeatherStationData;

public class GetWeatherStationDataResult {

    private static GetWeatherStationDataResult NOT_FOUND =
            new GetWeatherStationDataResult(null, null, null);

    private final WeatherStationData result;
    private final String host;
    private final Integer port;

    private GetWeatherStationDataResult(WeatherStationData result, String host,
            Integer port) {
        this.result = result;
        this.host = host;
        this.port = port;
    }

    public static GetWeatherStationDataResult found(WeatherStationData data) {
        return new GetWeatherStationDataResult(data, null, null);
    }

    public static GetWeatherStationDataResult foundRemotely(String host, int port) {
        return new GetWeatherStationDataResult(null, host, port);
    }

    public static GetWeatherStationDataResult notFound() {
        return NOT_FOUND;
    }

    public Optional&lt;WeatherStationData&gt; getResult() {
        return Optional.ofNullable(result);
    }

    public Optional&lt;String&gt; getHost() {
        return Optional.ofNullable(host);
    }

    public OptionalInt getPort() {
        return port != null ? OptionalInt.of(port) : OptionalInt.empty();
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>また、 <code>getMetaData()</code> のリターンタイプも定義しなければなりません (
<code>aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/PipelineMetadata.java</code>
)。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme.kafka.streams.aggregator.streams;

import java.util.Set;

public class PipelineMetadata {

    public String host;
    public Set&lt;String&gt; partitions;

    public PipelineMetadata(String host, Set&lt;String&gt; partitions) {
        this.host = host;
        this.partitions = partitions;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>最後に、RESTエンドポイントクラスを更新する必要があります。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme.kafka.streams.aggregator.rest;

import java.net.URI;
import java.net.URISyntaxException;
import java.util.List;

import javax.enterprise.context.ApplicationScoped;
import javax.inject.Inject;
import javax.ws.rs.Consumes;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.Response.Status;

import org.acme.kafka.streams.aggregator.streams.GetWeatherStationDataResult;
import org.acme.kafka.streams.aggregator.streams.KafkaStreamsPipeline;
import org.acme.kafka.streams.aggregator.streams.PipelineMetadata;

@ApplicationScoped
@Path("/weather-stations")
public class WeatherStationEndpoint {

    @Inject
    InteractiveQueries interactiveQueries;

    @GET
    @Path("/data/{id}")
    @Consumes(MediaType.APPLICATION_JSON)
    @Produces(MediaType.APPLICATION_JSON)
    public Response getWeatherStationData(@PathParam("id") int id) {
        GetWeatherStationDataResult result = interactiveQueries.getWeatherStationData(id);

        if (result.getResult().isPresent()) {                     <i class="conum" data-value="1"></i><b>(1)</b>
            return Response.ok(result.getResult().get()).build();
        }
        else if (result.getHost().isPresent()) {                  <i class="conum" data-value="2"></i><b>(2)</b>
            URI otherUri = getOtherUri(result.getHost().get(), result.getPort().getAsInt(),
                    id);
            return Response.seeOther(otherUri).build();
        }
        else {                                                    <i class="conum" data-value="3"></i><b>(3)</b>
            return Response.status(Status.NOT_FOUND.getStatusCode(),
                    "No data found for weather station " + id).build();
        }
    }

    @GET
    @Path("/meta-data")
    @Produces(MediaType.APPLICATION_JSON)
    public List&lt;PipelineMetadata&gt; getMetaData() {                 <i class="conum" data-value="4"></i><b>(4)</b>
        return interactiveQueries.getMetaData();
    }

    private URI getOtherUri(String host, int port, int id) {
        try {
            return new URI("http://" + host + ":" + port + "/weather-stations/data/" + id);
        }
        catch (URISyntaxException e) {
            throw new RuntimeException(e);
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>データはローカルで見つかったので、それを返す。</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>データは他のノードで管理されているので、指定されたキーのデータが他のノードに保存されている場合は、リダイレクト(HTTPステータスコード303)で返信する。</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>指定されたウェザーステーションIDに対するデータが見つからなかった。</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>アプリケーションクラスターを形成しているすべてのホストの情報を表示する。</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>ここで再び <code>aggregator</code> サービスを停止してリビルドします。そして、3つのインスタンスを起動してみましょう。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">./mvnw clean package -f aggregator/pom.xml
docker-compose stop aggregator
docker-compose up --build -d --scale aggregator=3</code></pre>
</div>
</div>
<div class="paragraph">
<p>3つのインスタンスのいずれかでREST
APIを呼び出す場合、要求されたウェザーステーションIDの集約は、クエリを受信したノードにローカルに格納されるか、他の2つのノードのいずれかに格納されるかのどちらかであるかもしれません。</p>
</div>
<div class="paragraph">
<p>Docker Composeのロードバランサーがラウンドロビン方式で <code>aggregator</code>
サービスにリクエストを配信するので、実際のノードを直接呼び出すことにします。アプリケーションはREST経由ですべてのホスト名の情報を公開しています。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">http aggregator:8080/weather-stations/meta-data

HTTP/1.1 200 OK
Connection: keep-alive
Content-Length: 202
Content-Type: application/json
Date: Tue, 18 Jun 2019 20:00:23 GMT

[
    {
        "host": "2af13fe516a9:8080",
        "partitions": [
            "temperature-values-2"
        ]
    },
    {
        "host": "32cc8309611b:8080",
        "partitions": [
            "temperature-values-1"
        ]
    },
    {
        "host": "1eb39af8d587:8080",
        "partitions": [
            "temperature-values-0"
        ]
    }
]</code></pre>
</div>
</div>
<div class="paragraph">
<p>レスポンスに表示されている 3 つのホストのうちの 1 つからデータを取得します (実際のホスト名は異なります)。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">http 2af13fe516a9:8080/weather-stations/data/1</code></pre>
</div>
</div>
<div class="paragraph">
<p>そのノードがキー「1」のデータを保持している場合は、このようなレスポンスが得られます。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-HTTP/1.1 200 OK Connection: keep-alive Content-Length: 74 Content-Type: hljs" data-lang="HTTP/1.1 200 OK Connection: keep-alive Content-Length: 74 Content-Type:">application/json Date: Tue, 11 Jun 2019 19:16:31 GMT

{
  "avg": 11.9,
  "count": 259,
  "max": 50.0,
  "min": -30.1,
  "stationId": 1,
  "stationName": "Hamburg"
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>そうでない場合、サービスはリダイレクトを送信します。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-HTTP/1.1 303 See Other Connection: keep-alive Content-Length: 0 Date: hljs" data-lang="HTTP/1.1 303 See Other Connection: keep-alive Content-Length: 0 Date:">Tue, 18 Jun 2019 20:01:03 GMT Location:
http://1eb39af8d587:8080/weather-stations/data/1 ```

また、 `--follow option` を渡すことで _httpie_ が自動的にリダイレクトに従うようにすることもできます。

```bash http --follow 2af13fe516a9:8080/weather-stations/data/1 ```

== ネイティブ実行

Kafka
Streams用のQuarkusエクステンションを使用すると、GraalVMを介してストリーム処理アプリケーションをネイティブ実行することができます。

`producer` と `aggregator` アプリケーションをネイティブモードで実行するには、 `native` プロファイルを使用して
Maven ビルドを実行します。

[source, shell]
----
./mvnw clean package -f producer/pom.xml -Pnative -Dnative-image.container-runtime=docker
./mvnw clean package -f aggregator/pom.xml -Pnative -Dnative-image.container-runtime=docker
----

ここで、 `QUARKUS_MODE` という名前の環境変数を作成し、値を"native"に設定します。

[source, shell]
----
export QUARKUS_MODE=native
----

これは、 `producer` と `aggregator` のイメージをビルドする際に正しい `Dockerfile` を使用するために Docker
Compose ファイルで使用されます。Kafka Streams アプリケーションは、ネイティブモードでは 50 MB 未満の RSS
で動作します。そのためには、 `aggregator/src/main/docker/Dockerfile.native` のプログラム呼び出しに
`Xmx` オプションを追加します。

[source, shell]
----
CMD ["./application", "-Dquarkus.http.host=0.0.0.0", "-Xmx32m"]
----

ここで、上記のようにDocker Composeを起動します(コンテナーイメージのリビルドを忘れずに)。

== Kafka Streams Health Checks

`quarkus-smallrye-health` のエクステンションを使用している場合は、 `quarkus-kafka-streams`
が自動的に以下を追加します。

* `quarkus.kafka-streams.topics` プロパティーで宣言されたすべてのトピックが作成されているかどうかを検証するための
  Readiness ヘルスチェック
* Kafka Streams の状態に基づく Liveness ヘルスチェック

So when you access the `/health` endpoint of your application you will have
information about the state of the Kafka Streams and the available and/or
missing topics.

これは、ステータスが `DOWN` になった場合の例です。
[source, subs=attributes+]
----
curl -i http://aggregator:8080/health

HTTP/1.1 503 Service Unavailable
content-type: application/json; charset=UTF-8
content-length: 454

{
    "status": "DOWN",
    "checks": [
        {
            "name": "Kafka Streams state health check",  <i class="conum" data-value="1"></i><b>(1)</b>
            "status": "DOWN",
            "data": {
                "state": "CREATED"
            }
        },
        {
            "name": "Kafka Streams topics health check",  <i class="conum" data-value="2"></i><b>(2)</b>
            "status": "DOWN",
            "data": {
                "available_topics": "weather-stations,temperature-values",
                "missing_topics": "hygrometry-values"
            }
        }
    ]
}
----
&lt;1&gt; Liveness health check. Also available at `/health/live` endpoint.
&lt;2&gt; Readiness health check. Also available at `/health/ready` endpoint.

そのため、ご覧のように `quarkus.kafka-streams.topics` のいずれかが欠けているか、Kafka Streams の
`state` が `RUNNING` でないとすぐにステータスが `DOWN` になります。

トピックがない場合、 `Kafka Streams topics health check` .の `data` フィールドに
`available_topics` キーは表示されません。また、トピックがない場合は、 `Kafka Streams topics health
check` の `data` フィールドに `missing_topics` キーは表示されません。

もちろん、 `quarkus-kafka-streams`
エクステンションのヘルスチェックを無効にすることもできます。`application.properties` の中で
`quarkus.kafka-streams.health.enabled` を `false` にしてください。

Obviously you can create your liveness and readiness probes based on the
respective endpoints `/health/live` and `/health/ready`.

=== Liveness health check

Here is an example of the liveness check: ``` curl -i
http://aggregator:8080/health/live

HTTP/1.1 503 Service Unavailable content-type: application/json;
charset=UTF-8 content-length: 225

{
    "status": "DOWN",
    "checks": [
        {
            "name": "Kafka Streams state health check",
            "status": "DOWN",
            "data": {
                "state": "CREATED"
            }
        }
    ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>state</code> is coming from the <code>KafkaStreams.State</code> enum.</p>
</div>
<div class="sect2">
<h3 id="readiness-health-check"><a class="anchor" href="#readiness-health-check"></a>Readiness health check</h3>
<div class="paragraph">
<p>Here is an example of the readiness check: <code>`</code> curl -i
<a href="http://aggregator:8080/health/ready" class="bare">http://aggregator:8080/health/ready</a></p>
</div>
<div class="paragraph">
<p>HTTP/1.1 503 Service Unavailable content-type: application/json;
charset=UTF-8 content-length: 265</p>
</div>
<div class="paragraph">
<p>{
    "status": "DOWN",
    "checks": [
        {
            "name": "Kafka Streams topics health check",
            "status": "DOWN",
            "data": {
                "missing_topics": "weather-stations,temperature-values"
            }
        }
    ]
}</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">== さらに詳しく

This guide has shown how you can build stream processing applications using
Quarkus and the Kafka Streams APIs, both in JVM and native modes.  For
running your KStreams application in production, you could also add health
checks and metrics for the data pipeline.  Refer to the Quarkus guides on
link:microprofile-metrics[metrics] and link:microprofile-health[health
checks] to learn more.

== 設定リファレンス

:leveloffset: +1

[.configuration-legend]
icon:lock[title=Fixed at build time] Configuration property fixed at build
time - All other configuration properties are overridable at runtime
[.configuration-reference.searchable, cols="80,.^10,.^10"]
|===


h|[[quarkus-kafka-streams_configuration]]link:#quarkus-kafka-streams_configuration[Configuration property]

h|タイプ
h|デフォルト

a|icon:lock[title=Fixed at build time] [[quarkus-kafka-streams_quarkus.kafka-streams.health.enabled]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.health.enabled[quarkus.kafka-streams.health.enabled]`

[.description]
--
Whether or not a health check is published in case the smallrye-health extension is present (defaults to true).
--|boolean
|`true`


a| [[quarkus-kafka-streams_quarkus.kafka-streams.application-id]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.application-id[quarkus.kafka-streams.application-id]`

[.description]
--
A unique identifier for this Kafka Streams application. If not set, defaults to quarkus.application.name.
--|string
|`${quarkus.application.name}`


a| [[quarkus-kafka-streams_quarkus.kafka-streams.bootstrap-servers]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.bootstrap-servers[quarkus.kafka-streams.bootstrap-servers]`

[.description]
--
A comma-separated list of host:port pairs identifying the Kafka bootstrap server(s)
--|list of host:port
|`localhost:9012`


a| [[quarkus-kafka-streams_quarkus.kafka-streams.application-server]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.application-server[quarkus.kafka-streams.application-server]`

[.description]
--
A unique identifier of this application instance, typically in the form host:port.
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.topics]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.topics[quarkus.kafka-streams.topics]`

[.description]
--
A comma-separated list of topic names. The pipeline will only be started once all these topics are present in the Kafka cluster.
--|list of string
|required icon:exclamation-circle[title=Configuration property is required]


a| [[quarkus-kafka-streams_quarkus.kafka-streams.schema-registry-key]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.schema-registry-key[quarkus.kafka-streams.schema-registry-key]`

[.description]
--
The schema registry key. e.g. to diff between different registry impls / instances as they have this registry url under different property key. Red Hat / Apicurio - apicurio.registry.url Confluent - schema.registry.url
--|string
|`schema.registry.url`


a| [[quarkus-kafka-streams_quarkus.kafka-streams.schema-registry-url]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.schema-registry-url[quarkus.kafka-streams.schema-registry-url]`

[.description]
--
The schema registry url.
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.security.protocol]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.security.protocol[quarkus.kafka-streams.security.protocol]`

[.description]
--
The security protocol to use See https://docs.confluent.io/current/streams/developer-guide/security.html++#++security-example
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.jaas-config]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.jaas-config[quarkus.kafka-streams.sasl.jaas-config]`

[.description]
--
JAAS login context parameters for SASL connections in the format used by JAAS configuration files
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.client-callback-handler-class]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.client-callback-handler-class[quarkus.kafka-streams.sasl.client-callback-handler-class]`

[.description]
--
The fully qualified name of a SASL client callback handler class
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.login-callback-handler-class]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.login-callback-handler-class[quarkus.kafka-streams.sasl.login-callback-handler-class]`

[.description]
--
The fully qualified name of a SASL login callback handler class
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.login-class]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.login-class[quarkus.kafka-streams.sasl.login-class]`

[.description]
--
The fully qualified name of a class that implements the Login interface
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.kerberos-service-name]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.kerberos-service-name[quarkus.kafka-streams.sasl.kerberos-service-name]`

[.description]
--
The Kerberos principal name that Kafka runs as
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.kerberos-kinit-cmd]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.kerberos-kinit-cmd[quarkus.kafka-streams.sasl.kerberos-kinit-cmd]`

[.description]
--
Kerberos kinit command path
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.kerberos-ticket-renew-window-factor]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.kerberos-ticket-renew-window-factor[quarkus.kafka-streams.sasl.kerberos-ticket-renew-window-factor]`

[.description]
--
Login thread will sleep until the specified window factor of time from last refresh
--|double
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.kerberos-ticket-renew-jitter]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.kerberos-ticket-renew-jitter[quarkus.kafka-streams.sasl.kerberos-ticket-renew-jitter]`

[.description]
--
Percentage of random jitter added to the renewal time
--|double
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.kerberos-min-time-before-relogin]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.kerberos-min-time-before-relogin[quarkus.kafka-streams.sasl.kerberos-min-time-before-relogin]`

[.description]
--
Percentage of random jitter added to the renewal time
--|long
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.login-refresh-window-factor]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.login-refresh-window-factor[quarkus.kafka-streams.sasl.login-refresh-window-factor]`

[.description]
--
Login refresh thread will sleep until the specified window factor relative to the credential's lifetime has been reached-
--|double
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.login-refresh-window-jitter]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.login-refresh-window-jitter[quarkus.kafka-streams.sasl.login-refresh-window-jitter]`

[.description]
--
The maximum amount of random jitter relative to the credential's lifetime
--|double
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.login-refresh-min-period]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.login-refresh-min-period[quarkus.kafka-streams.sasl.login-refresh-min-period]`

[.description]
--
The desired minimum duration for the login refresh thread to wait before refreshing a credential
--|link:https://docs.oracle.com/javase/8/docs/api/java/time/Duration.html[Duration]
  link:#duration-note-anchor[icon:question-circle[], title=More information about the Duration format]
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.sasl.login-refresh-buffer]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.sasl.login-refresh-buffer[quarkus.kafka-streams.sasl.login-refresh-buffer]`

[.description]
--
The amount of buffer duration before credential expiration to maintain when refreshing a credential
--|link:https://docs.oracle.com/javase/8/docs/api/java/time/Duration.html[Duration]
  link:#duration-note-anchor[icon:question-circle[], title=More information about the Duration format]
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.protocol]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.protocol[quarkus.kafka-streams.ssl.protocol]`

[.description]
--
The SSL protocol used to generate the SSLContext
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.provider]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.provider[quarkus.kafka-streams.ssl.provider]`

[.description]
--
The name of the security provider used for SSL connections
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.cipher-suites]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.cipher-suites[quarkus.kafka-streams.ssl.cipher-suites]`

[.description]
--
A list of cipher suites
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.enabled-protocols]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.enabled-protocols[quarkus.kafka-streams.ssl.enabled-protocols]`

[.description]
--
The list of protocols enabled for SSL connections
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.truststore.type]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.truststore.type[quarkus.kafka-streams.ssl.truststore.type]`

[.description]
--
Store type
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.truststore.location]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.truststore.location[quarkus.kafka-streams.ssl.truststore.location]`

[.description]
--
Store location
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.truststore.password]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.truststore.password[quarkus.kafka-streams.ssl.truststore.password]`

[.description]
--
Store password
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.keystore.type]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.keystore.type[quarkus.kafka-streams.ssl.keystore.type]`

[.description]
--
Store type
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.keystore.location]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.keystore.location[quarkus.kafka-streams.ssl.keystore.location]`

[.description]
--
Store location
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.keystore.password]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.keystore.password[quarkus.kafka-streams.ssl.keystore.password]`

[.description]
--
Store password
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.key.type]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.key.type[quarkus.kafka-streams.ssl.key.type]`

[.description]
--
Store type
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.key.location]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.key.location[quarkus.kafka-streams.ssl.key.location]`

[.description]
--
Store location
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.key.password]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.key.password[quarkus.kafka-streams.ssl.key.password]`

[.description]
--
Store password
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.keymanager-algorithm]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.keymanager-algorithm[quarkus.kafka-streams.ssl.keymanager-algorithm]`

[.description]
--
The algorithm used by key manager factory for SSL connections
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.trustmanager-algorithm]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.trustmanager-algorithm[quarkus.kafka-streams.ssl.trustmanager-algorithm]`

[.description]
--
The algorithm used by trust manager factory for SSL connections
--|string
|


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.endpoint-identification-algorithm]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.endpoint-identification-algorithm[quarkus.kafka-streams.ssl.endpoint-identification-algorithm]`

[.description]
--
The endpoint identification algorithm to validate server hostname using server certificate
--|string
|`https`


a| [[quarkus-kafka-streams_quarkus.kafka-streams.ssl.secure-random-implementation]]`link:#quarkus-kafka-streams_quarkus.kafka-streams.ssl.secure-random-implementation[quarkus.kafka-streams.ssl.secure-random-implementation]`

[.description]
--
The SecureRandom PRNG implementation to use for SSL cryptography operations
--|string
|

|===
[NOTE]
[[duration-note-anchor]]
.About the Duration format
====
期間のフォーマットは標準の `java.time.Duration` フォーマットを使用します。詳細は
link:https://docs.oracle.com/javase/8/docs/api/java/time/Duration.html#parse-java.lang.CharSequence-[Duration#parse()
javadoc] を参照してください。

数値で始まる期間の値を指定することもできます。この場合、値が数値のみで構成されている場合、コンバーターは値を秒として扱います。そうでない場合は、
`PT` が暗黙的に値の前に付加され、標準の `java.time.Duration` 形式が得られます。
====

:leveloffset!:</code></pre>
</div>
</div>
</div>
</div>
</div>
    </div>
  </div>
</div>

  </div>

  <div class="content project-footer">
  <div class="footer-section">
    <div class="logo-wrapper">
      <a href="/"><img src="/assets/images/quarkus_logo_horizontal_rgb_reverse.svg" class="project-logo" title="Quarkus"></a>
    </div>
  </div>
  <div class="grid-wrapper">
    <p class="grid__item width-3-12">Quarkus はオープンです。このプロジェクトの全ての依存関係は<a href='https://www.apache.org/licenses/LICENSE-2.0' target='_blank'>Apache Software License 2.0</a>または互換性のあるライセンスの元で利用出来ます。<br /><br />このウェブサイトは <a href='https://jekyllrb.com/' target='_blank'>Jekyll</a> で構築されており、<a href='https://pages.github.com/' target='_blank'>Github Pages</a>にホストされており、完全にオープンソースです。改善したい場合、 <a href='https://github.com/quarkusio/quarkusio.github.io' target='_blank'>ウェブサイトをフォークし</a>、修正してみせてください。</p>

    
      <div class="width-1-12 project-links">
        <span>ナビゲーション</span>
        <ul class="footer-links">
          
            <li><a href="/">ホーム</a></li>
          
            <li><a href="/guides">ガイド</a></li>
          
            <li><a href="/community/#contributing">貢献</a></li>
          
            <li><a href="/faq">FAQ</a></li>
          
            <li><a href="/get-started">はじめに</a></li>
          
        </ul>
      </div>
    
      <div class="width-1-12 project-links">
        <span>貢献</span>
        <ul class="footer-links">
          
            <li><a href="https://twitter.com/quarkusio">フォロー</a></li>
          
            <li><a href="https://github.com/quarkusio">GitHub</a></li>
          
            <li><a href="/security">セキュリティポリシー</a></li>
          
        </ul>
      </div>
    
      <div class="width-2-12 project-links">
        <span>サポート</span>
        <ul class="footer-links">
          
            <li><a href="https://stackoverflow.com/questions/tagged/quarkus">Stack Overflow</a></li>
          
            <li><a href="https://quarkusio.zulipchat.com">チャットルーム</a></li>
          
            <li><a href="https://groups.google.com/forum/#!forum/quarkus-dev">フォーラム</a></li>
          
        </ul>
      </div>
    

    
      <div class="width-4-12 more-links">
        <span>Quarkusはコミュニティプロジェクトで構成されています：</span>
        <ul class="footer-links">
          
            <li><a href="https://vertx.io/" target="_blank">Eclipse Vert.x</a></li>
          
            <li><a href="https://smallrye.io" target="_blank">SmallRye</a></li>
          
            <li><a href="https://hibernate.org" target="_blank">Hibernate</a></li>
          
            <li><a href="https://netty.io" target="_blank">Netty</a></li>
          
            <li><a href="https://resteasy.github.io" target="_blank">RESTEasy</a></li>
          
            <li><a href="https://camel.apache.org" target="_blank">Apache Camel</a></li>
          
            <li><a href="https://microprofile.io" target="_blank">Eclipse MicroProfile</a></li>
          
            <li><a href="https://code.quarkus.io/" target="_blank">等々...</a></li>
          
        </ul>
      </div>
    
  </div>
</div>

  <div class="content redhat-footer">
  <div class="grid-wrapper">
    <span class="licence">
      <i class="fab fa-creative-commons"></i><i class="fab fa-creative-commons-by"></i> <a href="https://creativecommons.org/licenses/by/3.0/" target="_blank">CC by 3.0</a> | <a href="https://www.redhat.com/en/about/privacy-policy">Privacy Policy</a>
    </span>
    <span class="redhat">
      Sponsored by
    </span>
    <span class="redhat-logo">
      <a href="https://www.redhat.com/" target="_blank"><img src="/assets/images/redhat_reversed.svg"></a>
    </span>
  </div>
</div>


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>
  <script type="text/javascript" src="/assets/javascript/mobile-nav.js"></script>
  <script type="text/javascript" src="/assets/javascript/scroll-down.js"></script>
  <script src="/assets/javascript/satellite.js" type="text/javascript"></script>
  <script src="/guides/javascript/config.js" type="text/javascript"></script>
  <script src="/assets/javascript/search-filter.js" type="text/javascript"></script>
  <script src="/assets/javascript/guides-version-dropdown.js" type="text/javascript"></script>
  <script src="/assets/javascript/back-to-top.js" type="text/javascript"></script>
</body>

</html>
